{"split": {"self_supervised_train": 58486, "self_supervised_val": 38992, "supervised_train": 8664, "supervised_val": 2167}, "aug_transforms": "class ContrastiveTransformations(object):\n    \"\"\"\n    Apply a series of augmentations to the input image.\n\n    Args:\n        k (int): Number of augmentations to apply.    \n    \"\"\"\n\n    def __init__(self, k=5):\n        self.k = k\n\n        # Base PIL transforms\n        self.base_transforms = transforms.Compose([\n            ProbabilisticTransform(transforms.RandomResizedCrop(size=IMAGE_SIZE, scale=(0.5, 1.0)), p=0.8),\n            transforms.RandomHorizontalFlip(p=0.8),\n            transforms.RandomVerticalFlip(p=0.8),\n            ProbabilisticTransform(transforms.ColorJitter(brightness=0.3, contrast=0.3), p=0.8),\n            ProbabilisticTransform(transforms.RandomRotation(degrees=180), p=0.8),\n            ProbabilisticTransform(transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=10), p=0.8),\n            ProbabilisticTransform(transforms.GaussianBlur(kernel_size=(3, 3)), p=0.8)\n        ])\n\n        # Convert PIL to tensor\n        self.to_tensor = transforms.ToTensor()\n\n        # Tensor-specific transforms\n        self.tensor_transforms = transforms.Compose([\n            AddNoise(noise_std=0.05, p=0.8),  # Add noise 50% of the time\n            Cutout(mask_size=16, p=0.8, replace=0.0),  # Add Cutout\n            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n            transforms.Normalize(mean=[0.5], std=[0.5]),\n        ])\n\n    def __call__(self, x):\n        augmented_images = []\n        for _ in range(self.k):\n            # Apply base transforms\n            img = self.base_transforms(x)\n            # Convert to tensor and apply tensor transforms\n            img_tensor = self.to_tensor(img)\n            img_tensor = self.tensor_transforms(img_tensor)\n            augmented_images.append(img_tensor)\n\n        return augmented_images\n    \n# Save the augmentation information\ndata_dict['aug_transforms'] = _ih[-1]", "k": 2, "image_size": 224}